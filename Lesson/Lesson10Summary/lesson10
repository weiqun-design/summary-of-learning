1. 排序学习（learning to rank）：推荐系统，搜索，广告的核心算法之一（LTR不仅被应用到搜索中，也应用到所有与排序相关的各种需求中）
2. Ranking模型，基于相关度和基于重要性进行排序
3. 基于重要性的ranking，仅根据网页之间的图结构来判断文档的重要程度，比如pagerank、trustrank等
4. 基于相关度的ranking，有监督的机器学习过程，对每一个给定的query-doc对，抽取特征，通过日志挖掘或者人工标注的方法获取真实数据标注。
   然后通过排序模型，使得输入能够和实际的数据相似。
5. 排序学习场景
   推荐系统，基于历史行为的"猜你喜欢"
   搜索排序，基于某query进行的结果排序，期望用户选中的在排序结果中是靠前的=>有意识的被动推荐
   排序结果都很重要，采用用户想要点击或者booking的item就在结果列表前面
   排序学习是个性化结果，用于搜索列表、推荐列表、广告等场景。
6. 什么是LTR学习策略：1. 推荐不仅是预估问题，更应该关注排序问题
                    2. 传统的排序算法考虑的因素少，需要组合多种因素进行排序
                    3. 使用机器学习，目标是最小化损失函数，根据每次迭代的信息反馈，自动优化模型参数
                    4. 有监督的排序学习方法，通过训练数据=>ranking model
7. LTR的三种策略：PointWise 针对单一文档
                PairWise 关注文档的顺序关系
                ListWise 将一次query对应的所有搜索结果列表作为一个训练样例
8. PointWise排序学习（单点法）：构造特征及label
9. PointWise特征选择：item特征，评分，销量，价格等；
                    user特征，性别、年龄、偏好等；
                    user-item特征，是否看过词item，是否买过此item、对item的评价；
                    场景特征：时间（节假日、早中晚）、地理位置等。
10. PointWise label构造：如展示过的item label设置为1，用户点击过的label为3，用户购买过的label为7。
11. PointWise将训练样本转换为多分类问题，或者回归问题。如果是多分类问题，模型最后输出只能是1，3，7，如果转换为回归问题，常采用LR、GBDT等来解决
12. 优点是简单，不足在于没有考虑样本之间的位置信息（doc之间的相对顺序）
13. Pairwise排序学习（配对法）：比较流行的LTR学习方法，将排序问题转换为二元分类问题；
                             接收到用户查询后，返回相关文档列表，确定文档之间的先后顺序关系（多个pair的排序问题）
                             对于同一个查询的相关文档集中，对任何两个不同label的文档，都可以得到一个训练实例（di，dj），如果di>dj则赋值1，反之-1
                             没有考虑文档出现在搜索列表中的位置，排在搜索结果前面的文档更为重要，如果靠前的文档出现判断错误，代价会很高。
                             主要算法：SVM Rank，RankBoost（2003），RankNet（2007）
14. ListWise排序学习（列表法）：它是将每个query对应的所有搜索结果列表作为一个训练样本
                             根据训练样例训练得到最优评分函数F，对应新的查询，评分F对每个文档打分，然后根据得分由高到低排序，即为最终的排序结果
                             直接考虑整体序列，针对Ranking评价指标（比如MAP，NDCG）进行优化
                             主要算法：ListNet，AdaRank，SoftRank，LambdaRank，LambdaMART等，LambdaMART是对RankNet和LambdaRank的改进，在Yahoo
                             Learning to rank challenge比赛中的冠军模型
15. 评测指标MAP: Mean Average Precision, 平均准确率
16. 对于每个真实相关的文档，考虑其在模型排序结果中的位置P，统计该位置之前的文档集合的分类准确率，取这些准确率的平均值
17. 随着网络深度加大，预测准确率在提升，但增加到第4层之后，MAP已经变化不大了
18. 增加了观看历史之外的特征，对预测准确率提升很明显
19. 评测指标CG，累积增益（cumulative gain），只考虑了相关性，没有考虑到位置的因素。理想结果c1，c2，c3，实际结果c3，c2，c1，CG不变。相关性分数的和。
20. DCG（Disconted CG），折损累积增益，在每一个CG的结果上除以一个折损值，为了让排名靠前的结果能影响最后的结果。排序越往后价值越低。
21. IDCG (ideal DCG) 理想情况下最大的DCG值
22. NDCG (Normalized DCG) 归一化贴现累积收益，综合考虑模型排序结果和真实序列之间的关系，最终使用的排序指标。NDCG = DCG/IDCG
23. MRR平均倒数排名， Mean Reciprocal Rank，把相关文档在查询结果中的排序倒数作为准确度，然后再取平均。优点是计算简单，不足在于仅仅考虑了相关性最强的文档所在的位置带来的损失。
24. 排序算法：RankNet，LambdaRank和LambdaMART在yahoo learning to rank challenge等比赛中表现出很好的排序结果。
25. RankNet是基于神经网络的排序算法。
26. 在RankNet的基础上加入了lambda梯度 => lambdaRank
27. lambda梯度和MART（GBDT也称为MART，梯度提升树）结合 => lambdaMart
28. RankNet: 目标就是所有query，都能对doc结果按照相关性进行排序；比如搜索开课吧，百度搜索页面返回了10条相关结果，人们的浏览顺序是从上到下的，
             因此排在上面的要比排在下面的相关性更高
29. RankNet是基于神经网络的排序学习方法，依赖于每个文档对，定义了一个基于概率的损失函数，运用神经网络和梯度下降法试图最小化一个交叉熵损失函数，终极目标是得到一个带参数的得分函数。
    根据这个函数就可以求得文档对的相对排序位置
30. lambdaRank在此基础上考虑评价指标Z（比如NDCG，ERR），在i，j交换位置后评价指标Z的变化差值
31. Ranklib工具 https：//sourceforge.net/p/lemur/wiki/RankLib/
32. 推荐系统和搜索排序，推荐系统，采用pointwise模型较多，预测出来的分数，具有实际的物理意义，代表了目标用户点击item的预测概率
33. 推荐是发散的，无意识的主动推荐，相比search而言，排序准确性不一定是最重要的
34. 多样性也导致了推荐场景没有像搜索异常适合做pairwise的样本
35. 搜索排序，是基于某query进行的结果排序，期望用户选中的在排序结果中是靠前的=>有意识的被动推荐
36. 排序模型思维维度：业务场景：推荐 or 搜索排序
    是否关注query内的相对排序 => pointWise or ListWise, 构造排序学习的数据样本，选择适合的模型
37. Airbnb（爱彼迎是一家联系旅游人士和家有空房出租的房主的服务型网站）个性化推荐。
38. 短租市场：大部分的用户很少会多次预定同一类型的房间；房间分时段，只能在某段时间内被某一个用户预定；低频事件（对于大部分预定用户），同一个地方预定酒店更是低频
39. 实时个性化：搜索排序，相似房源
40. airbnb场景特定：双边的房屋短租平台（顾客，房东）
                  顾客通过搜索或者系统推荐找到房源=>贡献了Airbnb 99%的booking
                  一个顾客很少会预定同一个房源多次
                  一个房源在某时间段内只能被一个顾客租用
                  数据存在严重的稀疏性
41. Airbnb个性化推荐：针对搜索排序，相似房源土建进行实时个性化推荐。基于业务需求，考虑搜索的目标：点击率，新闻的观看时长，提高商品购买的转化率等等。
    与其他商品不同，不是用户想定就能定上房源
    对于双边市场，需要同时为市场两端用户买家和卖家提供服务
    双边的推荐，既需要考虑用户预定，也需要考虑房东是否接收预定
    对于query，同时为host和guest优化搜索结果
    顾客角度：需要根据位置，价格，类型，评论等因素排序来获得客户喜欢的listing
    房东角度：需要过滤掉那些有坏的评论，宠物，停留时间，人数等其他因素而拒绝guest的listing，将这些listing排列的低一点
    采用learning to rank来做，将问题转换为pairwise regression问题，将预定的listing作为正样本，拒绝的作为负样本。
42. 将每个房源 => 房源embendding
    数据集由N个用户的点击会话session组成，其中每个会话定义为一个由用户点击的M个房源id组成的不间断序列
    只要用户连续两次嗲集时间间隔超过30分钟，就认为是一个新的session
    目标是通过集合S，学习出每个房源listing的d维，让相似listing在embedding空间中距离更近
    采用类似与skip-gram，用窗口中央的房源，取预测上线文的房源
43. airbnb加入同一区域的listing集合中进行随机抽样
44. list embedding的离线评估：在使用基于embedding的推荐系统尽心线上搜索测试前，需要进行多次离线测试。目的是比较不同参数训练出来的embedding，决定embedding维度，算法思路等。
                            评估标准，测试用户最近的点击推荐的房源，有多大可能最终会产生预定。
                            step1，获取用户最近点击的房源，以及需要排序的房源候选列表，用户最终预定的房源
                            step2，计算点击房源和候选房源在embedding空间的余弦相似度
                            step3，对候选房源按照相似度进行排序，观察最终预订的房源在排序中的位置。
45. list embedding的冷启动： 每天都有新的房源产生，冷启动在所难免
                            房主上传新房源时需要上传3个特征，位置，价格，房源类型（包括整个房源，独立房间，合住房间3个类别）
                            在和新上传房源具有相同类型和相同价格区间的房源中，找到3个地理位置最接近的房源，用这3个房源的embedding来平均作为新房源的embedding
                            能覆盖到98%的新listing
46. list embedding的评估：用多种方式验证embedding的有效性
                         K-means聚类，将embedding进行聚类，然后可以发现其在地理位置上的区分度
                         embedding之间的余弦相似度
                         不同类型的listing之间的余弦相似度
                         不同价格范围的listing之间的余弦相似度
                         除了基础属性（价格，地理位置）很明显的能直接获取，还有隐属性可以通过embedding来发现，比如房屋的文理
                         计算来每个listing embedding的k近邻，并对比这个listing和k近邻 => embedding evaluation tool
47. 每个airbnb房源详情页面都包含一个相似房源的轮播，推荐与当前房源相似并且可以在相同时间段内预定的房源
    在有了listing embedding之后，进行了A/B test，基于embedding的推荐使相似房源点击率增加了21%，通过相似房源产生的预定增加了4.9%
48. 在基于embedding的推荐中，相似房源是通过在list embedding空间中找到k个最近邻居
49. listing embedding不能够解决的问题：需要基于当前的点击来计算，只提取来用户的short-term兴趣，只能用于相似房源场景中，只针对同地区下的用户兴趣房源的挖掘
50. user type embedding和listing type embedding：以预定序列作为数据集；
    存在的问题：训练数据集会很小，因为相比点击，预定的数据小一个数量级；很多用户在过去只预定过一次，这些数据是没法用来训练模型；
    需要进一步去掉那些在平台上总共被预定的次数很少的listing，时间跨度太长，可能用户的喜欢偏好已经发生变化
51. user type embedding和listing type embedding：
    为了处理存在的问题，提出了学习type级别的embedding，而不是学习id级别的emebedding
    对于原始的listing数据，基于一些影星规则生成每个listing的类别
    目的是将原本稀疏的数据，变得稠密（基于类型）很多session出现了共现
















