1. predict wheel (模型）： 分类算法：LR， Decision Tree， Naive Bayes， SVM， KNN
                          矩阵分解：ALS-WR，FunkSVD，BiasSVD，SVD++
                          FM模型： FM，FFM，DeepFM，NFM， AFM，xDeepFM
                          树模型：GBDT，XGBOOST，DeepFM，NFM，AFM，xDeepFM
                          Attention模型：DIN，DIEN，DSIN，Transformer，BERT
                          Embedding：word2vec，deepwalk，Node2Vec，GCN
                          时间序列：AR，MA，ARMA，ARIMA，LSTM
                          强化学习：policy-based，value-based，actor-critic
2. 有监督学习，无监督学习，强化学习
   不仅仅是游戏AI
   在搜素排序，推荐系统，广告系统，只能客服中都有重要应用
3. AI的发展，1970s的专家系统，计算机科学家把自己的知识经验放到巨大的数据库中，通过判断规则写成程序，早期的自动驾驶所有规则需要事先编写好=>明知识，
   问题在于有很多知识是暗知识，人们无法穷举所有的路况和场景。
4. 早期人工智能1950s-1980s，机器学习1980s开始，深度学习2010s开始
5. predict的流派：符号学派，认为事情都是有因果的，机器可以自己摸索出规律，典型代表为决策树
                 贝叶斯学派，因果之间不是必然发生，是有一定概率的，即P（A|B），典型代表为朴素贝叶斯
                 类推学派，通过类比可以让我们学习到很多未知的知识，所以我们需要先定义相似度，通过相似度进行发现
                 联结学派，模仿人脑神经元的工作原理，所有模式识别和记忆建立在神经元的不同连接方式上，典型代表为神经网络，深度学习
                 进化学派，认为以上模型都是先入为主，实际上世界太复杂，找不到规律，需要让给上帝通过基因选择来适者生存，典型代表为遗传算法
6. 预测场景：新零售：CTR预估、预估下个月每个产品和商店的总销售额、预测用户何时会流失、用户复购预测、优惠券使用预测、预测用户将再次购买哪些产品、
            预测页面的未来流量、销售策略组合购物篮问题
            城市计算：出租车行程的总时间，交通流量预测，PM2.5预测，物流预测
            价格预测：北上广深房价，比特币价格走势，沪市指数预测，租房价格预测
            竞猜：篮球联赛，预测哪个团队能够获胜
            医疗：肺癌检测，预测17个身体区域存在威胁的概率
            金融科技：风险控制，失信企业识别，用户违约预测，潜在企业客户预测
            HR：员工离职预测
7. Google的AI预测医院病人的死亡时间，准确率达95%
8. AutoML的崛起，需要机器学习专业知识的人进行试验：特征提取、模型选择、参数调节等机器学习的各个方面
   需要大量的时间，比如一个典型的10层网络一般具有10^10个候选网络
   成本高，美国机器学习工程师平均薪酬14.6万美金/年，国内大厂平均55万/年
9. AutoML的组成部分：包括：自动传统机器学习，自动深度学习
                        自动传统机器学习：自动数据预处理、自动特征处理、自动算法选择与配置
                        自动深度学习：神经网络的自动训练、网络结构搜索
10. AutoML的pipeline过程：数据准备：数据收集：数据合成
                                          数据搜索
                                 数据清理：标准化
                                          缩放
                                          定量特征二值化
                                          one-hot编码定性特征
                                          用平均值填充缺失值
                         特征工程：特征选择
                                 特征构造
                                 特征提取
                         模型生成：模型结构：整体结构
                                          基于单元的结构
                                          层次结构
                                          基于网络态射结构
                                  参数优化
                         模型评估：传统机器学习
                                  降低评估成本：低保真
                                              迁移学习
                                              代理
                                              早停法
11. 在工业界，认为数据和特征决定了模型的上限，而模型和算法只是尽量把上限跑出来
12. 特征选择后的新特征是原来特征的一个子集
13. 特征抽取后的新特征是原来特征的一个映射，比如对于数据采用统计技术（count，min，max，avg，std，median等方式）
14. 构造新特征的过程，帮助提高模型的预测准确性和泛化性
15. 模型生成：传统模型：决策树，SVM，KNN，XGBoost等，工具有TPOT，Auto-sklearn等
16. NAS(Neural Architecture Search): 包括：搜索空间（模型结构），搜索策略（参数自动化），性能评估。
17. 原理：给定一个搜索空间的候选神经网络结构集合，采用某种策略从集合中找出最优网络结构
18. NAS 基于整体结构生成一个完整的网络结构，不足在于，网络结构搜索空间过大，生成的网络结构缺乏可迁移性和灵活性
19. NAS 基于单元的结构，需要叠加若干个单元结构，最终形成完整的网络结构（类似于链式结构的方式生成整个结构）搜索空间从整个网络缩减到更小的单元
    结构，同时可以通过增减单元结构的数量来改变网络结构
20. 优点：解决来整体结构网络搜索存在的问题
21. 不足：单元结构的数量和连接方式不确定，大都需要依赖人的经验而定
22. NAS搜索空间：一般的网络设计方法是首先设计出一个网络结构，然后训练它，并在验证集上查看它的性能表现，如果表现较差，
                则重新设计一个网络=>不足在于网络设计效率低，耗费大量时间
                基于网络态射结构方法能够在原有的网络结构基础上做修改，很大程度上能保留原网络的优点，同时变现不比原网络差
                （因为特殊的变换方式，所以可以保证新的网络结构还原成原网络）
23. NAS搜索策略，定义了使用怎样的算法可以快速、准确找到最优的网络结构参数配置
24. 常用的搜索策略：网格和随机搜索，grid & random search
                  强化学习，reinforcement learning
                  进化算法，evolutionary alogrithm
                  贝叶斯优化，bayesian opimization
                  梯度下降，gradient descent
                  其中强化学习和进化学习是主流算法
25. 强化学习：RL有四个要素：agent，action，environment，reward。
26. 强化学习是通过奖励或乘法来学习怎样选择能产生最大积累奖励的行动的算法
27. 进化学习：在进化学习中，我们需要一个模型簇，每一饿模型，就是个体，这些模型的准确度就是度量个体质量的指标；在一个进化过程中，工作者随机
             从模型簇中选出两个个体模型。根据优胜劣汰原则，将不合适的模型从模型簇中被剔除，而更优的模型则成为母体，进行繁殖；通过这一过程，
             工作者实际上是创造了一个母体的副本，并让这个副本随机发生变异。我们把这一修改过的副本称为子代。子代创造出来后，经过训练并在校验
             集上对它进行评估之后，把子代放回到模型簇中。此时，这个子代就成为母体继续进行上述步骤的进化。
28. 进化算法就是在随机选出的个体中择其优，不足是进化过程通常不稳定，最终的模型簇质量取决于随机变异。
29. 贝叶斯优化：很多时间都遵循正态分布，在贝叶斯调参过程中，假设参数组合是X，最终的评估结果为Y，目标是通过什么样的X可以取得最优的Y。假设超参数优化
    的过程是一个高斯过程。那么当我们随机遍历一定数据点后，就可以绘制整个数据的分布曲线。采用贝叶斯优化，就是不断使用先验点去预测后验知识。
    贝叶斯超参数优化：把参数组合对结果的影响看作一个高斯过程，把E&E策略看作一个自定义函数去衡量。
30. NAS性能评估：
    神经网络结构的好坏，指标包括精度（AUC， logloss，MSE，MAE）、速度
    最简单的方式，就是在数据集上进行标准的模型训练和模型验证，但计算成本很高
31. 降低性能评估的成本的方法：低保真、迁移学习、代理、早停法
32. 低保真：用一些低保真的训练集来训练模型，低保真在实际应用中可以有多种表达，比如训练更少的次数，用原始训练数据的一部分，低分辨率的图片，每一
    层用更少的滤波器等
33. 用这种低保真的训练集来测试优化算法来大大降低计算时间，但也存在一定的bias，不过选择最优的架构并不需要绝对数值，只需要有绝对值就可以
34. 迁移学习：参数级别的迁移，用之前已经训练好的模型权重参数对target问题进行赋值，从一个高起点的初值开始寻优将会大大地提高效率。在这类问题
    中，积累来大量的历史寻优数据，对新问题的寻优将会起到很大的帮助。
35. 目前整理到ppt46页





